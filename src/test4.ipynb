{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117c4156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on a GPU MIG instance\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "def check_mig_with_smi():\n",
    "    try:\n",
    "        output = subprocess.check_output([\"nvidia-smi\", \"-L\"], text=True)\n",
    "        return \"MIG\" in output\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "        return False\n",
    "\n",
    "if check_mig_with_smi():\n",
    "    print(\"Running on a GPU MIG instance\")\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "else:\n",
    "    print(\"Not running on a GPU MIG instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23927327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: Windows 10\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(f\"Platform: {platform.system()} {platform.release()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9edeb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from modelComp.FluidGPT_B import FluidGPT_B\n",
    "\n",
    "# load yaml file\n",
    "yaml_path = \"../conf/model/std-5.yaml\"\n",
    "import yaml\n",
    "\n",
    "\n",
    "class DotDict(dict):\n",
    "    def __init__(self, mapping=None):\n",
    "        super().__init__()\n",
    "        mapping = mapping or {} \n",
    "        for key, value in mapping.items():\n",
    "            self[key] = DotDict(value) if isinstance(value, dict) else value\n",
    "\n",
    "    def __getattr__(self, key):\n",
    "        try:\n",
    "            return self[key]\n",
    "        except KeyError:\n",
    "            raise AttributeError(f\"Key '{key}' not in config\")\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self[key] = value\n",
    "\n",
    "def load_yaml_as_dotdict(filepath):\n",
    "    with open(filepath, \"r\") as file:\n",
    "        data = yaml.safe_load(file) or {}  # for if yaml empty lined\n",
    "    return DotDict(data)\n",
    "\n",
    "cm = load_yaml_as_dotdict(yaml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0981ef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20183172\\AppData\\Local\\anaconda3\\envs\\grad311\\Lib\\site-packages\\torch\\functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4316.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FluidGPT_B(emb_dim=96,\n",
    "                    data_dim=[64, cm.temporal_bundling, cm.in_channels, 128, 128],\n",
    "                    patch_size=(cm.patch_size, cm.patch_size),\n",
    "                    hiddenout_dim=cm.hiddenout_dim,\n",
    "                    depth=cm.depth,\n",
    "                    stage_depths=cm.stage_depths,\n",
    "                    num_heads=cm.num_heads,\n",
    "                    window_size=cm.window_size,\n",
    "                    use_flex_attn=cm.use_flex_attn\n",
    "                    ).cuda()\n",
    "model.eval()\n",
    "# Load the model weights\n",
    "checkpoint_path = \"C:/Users/20183172/Documents/2024-II/prep/epoch=28-step=563673.ckpt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cuda\")\n",
    "state_dict = checkpoint[\"state_dict\"]\n",
    "new_state_dict = {k.replace(\"model.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4489ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(16, 5, 2, 128, 128).cuda()\n",
    "with torch.no_grad():\n",
    "    y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a1a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.DiskDatasetDiv import DiskDatasetDiv\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#dataset = DiskDatasetDiv(preproc_path='../datasets/prjs1359/preproc_amira-s6', temporal_bundling=1)\n",
    "dataset = DiskDatasetDiv(preproc_path='/datasets/preproc_pdegym-test', temporal_bundling=2)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=16, pin_memory=True, persistent_workers=True)\n",
    "dataset.avgnorm = dataset.avg\n",
    "dataset.stdnorm = dataset.std\n",
    "\n",
    "dataset.avgnorm, dataset.stdnorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533dcfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mdataloader\u001b[49m):\n\u001b[0;32m      2\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m      3\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mcuda()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(dataloader):\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    with torch.no_grad():\n",
    "        out = model(x)\n",
    "    print(f\"Batch {i+1}: Output shape: {out.shape}, Target shape: {y.shape}\")\n",
    "    if i == 0:\n",
    "        break  # Just test the first batch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# plot the x and y \n",
    "fig, ax = plt.subplots(3, 3, figsize=(12, 6))\n",
    "ax[0, 0].imshow(x[0, 0].cpu().numpy(), cmap='gray')\n",
    "ax[0, 1].imshow(y[0, 0].cpu().numpy(), cmap='gray')\n",
    "ax[1, 0].imshow(out[0, 0].cpu().numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704068f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grad311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
