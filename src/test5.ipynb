{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39eee6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on a GPU MIG instance\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['figure.facecolor'] = '#1F1F1F'\n",
    "plt.rcParams['axes.facecolor'] = '#1F1F1F'\n",
    "plt.rcParams['savefig.facecolor'] = '#1F1F1F'\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "def check_mig_with_smi():\n",
    "    try:\n",
    "        output = subprocess.check_output([\"nvidia-smi\", \"-L\"], text=True)\n",
    "        return \"MIG\" in output\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "        return False\n",
    "\n",
    "if check_mig_with_smi():\n",
    "    print(\"Running on a GPU MIG instance\")\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "else:\n",
    "    print(\"Not running on a GPU MIG instance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b59e7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch import einsum, nn\n",
    "\n",
    "\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x\n",
    "\n",
    "\n",
    "def Upsample(dim, dim_out):\n",
    "    return nn.Sequential(\n",
    "        nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
    "        nn.Conv2d(dim, dim_out, 3, padding=1),\n",
    "    )\n",
    "\n",
    "\n",
    "def Downsample(dim, dim_out):\n",
    "    # No More Strided Convolutions or Pooling\n",
    "    return nn.Sequential(\n",
    "        Rearrange(\"b c (h p1) (w p2) -> b (c p1 p2) h w\", p1=2, p2=2),\n",
    "        nn.Conv2d(dim * 4, dim_out, 1),\n",
    "    )\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups=8):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(dim, dim_out, 3, padding=1)\n",
    "        self.norm = nn.GroupNorm(groups, dim_out)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x, scale_shift=None):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if scale_shift is not None:\n",
    "            scale, shift = scale_shift\n",
    "            x = x * (scale + 1) + shift\n",
    "\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim, groups=8):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim, dim_out * 2),\n",
    "        )\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=groups)\n",
    "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb=None):\n",
    "        scale_shift = None\n",
    "        time_emb = self.mlp(time_emb)\n",
    "        time_emb = rearrange(time_emb, \"b c -> b c 1 1\")\n",
    "        scale_shift = time_emb.chunk(2, dim=1)\n",
    "\n",
    "        h = self.block1(x, scale_shift=scale_shift)\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head**-0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
    "        )\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = einsum(\"b h d i, b h d j -> b h i j\", q, k)\n",
    "        sim = sim - sim.amax(dim=-1, keepdim=True).detach()\n",
    "        attn = sim.softmax(dim=-1)\n",
    "\n",
    "        out = einsum(\"b h i j, b h d j -> b h i d\", attn, v)\n",
    "        out = rearrange(out, \"b h (x y) d -> b (h d) x y\", x=h, y=w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head**-0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "\n",
    "        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1), nn.GroupNorm(1, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
    "        )\n",
    "\n",
    "        q = q.softmax(dim=-2)\n",
    "        k = k.softmax(dim=-1)\n",
    "\n",
    "        q = q * self.scale\n",
    "        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n",
    "\n",
    "        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n",
    "        out = rearrange(out, \"b h c (x y) -> b (h c) x y\", h=self.heads, x=h, y=w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = nn.GroupNorm(1, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        channels=3,\n",
    "        self_condition=False,\n",
    "        resnet_block_groups=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # determine dimensions\n",
    "        self.channels = channels\n",
    "        self.self_condition = self_condition\n",
    "        input_channels = channels * (2 if self_condition else 1)\n",
    "\n",
    "        init_dim = dim\n",
    "        self.init_conv = nn.Conv2d(\n",
    "            input_channels, init_dim, 1, padding=0\n",
    "        )  # changed to 1 and 0 from 7,3\n",
    "\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        block_klass = partial(ResnetBlock, groups=resnet_block_groups)\n",
    "\n",
    "        # time embeddings\n",
    "        time_dim = dim * 4\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(dim),\n",
    "            nn.Linear(dim, time_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "        )\n",
    "\n",
    "        # layers\n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
    "                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
    "                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "                        (\n",
    "                            Downsample(dim_in, dim_out)\n",
    "                            if not is_last\n",
    "                            else nn.Conv2d(dim_in, dim_out, 3, padding=1)\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n",
    "            is_last = ind == (len(in_out) - 1)\n",
    "\n",
    "            self.ups.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        block_klass(dim_out + dim_in, dim_out, time_emb_dim=time_dim),\n",
    "                        block_klass(dim_out + dim_in, dim_out, time_emb_dim=time_dim),\n",
    "                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "                        (\n",
    "                            Upsample(dim_out, dim_in)\n",
    "                            if not is_last\n",
    "                            else nn.Conv2d(dim_out, dim_in, 3, padding=1)\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.out_dim = channels\n",
    "\n",
    "        self.final_res_block = block_klass(dim * 2, dim, time_emb_dim=time_dim)\n",
    "        self.final_conv = nn.Conv2d(dim, self.out_dim, 1)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        x = self.init_conv(x)\n",
    "        r = x.clone()\n",
    "\n",
    "        t = self.time_mlp(time)\n",
    "\n",
    "        h = []\n",
    "\n",
    "        for block1, block2, attn, downsample in self.downs:\n",
    "            x = block1(x, t)\n",
    "            h.append(x)\n",
    "\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "\n",
    "            x = downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        for block1, block2, attn, upsample in self.ups:\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = block1(x, t)\n",
    "\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = torch.cat((x, r), dim=1)\n",
    "\n",
    "        x = self.final_res_block(x, t)\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1196e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from scipy import integrate\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "eps = 0.001\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Unet(\n",
    "    dim=32,\n",
    "    channels=1,\n",
    "    dim_mults=(1, 2, 4),\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def euler_sampler(model, shape, sample_N):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z0 = torch.randn(shape, device=device)\n",
    "        x = z0.detach().clone()\n",
    "\n",
    "        dt = 1.0 / sample_N\n",
    "        for i in range(sample_N):\n",
    "            num_t = i / sample_N * (1 - eps) + eps\n",
    "            t = torch.ones(shape[0], device=device) * num_t\n",
    "            pred = model(x, t * 999)\n",
    "\n",
    "            x = x.detach().clone() + pred * dt\n",
    "\n",
    "        nfe = sample_N\n",
    "        return x.cpu(), nfe\n",
    "\n",
    "\n",
    "def to_flattened_numpy(x):\n",
    "    return x.detach().cpu().numpy().reshape((-1,))\n",
    "\n",
    "\n",
    "def from_flattened_numpy(x, shape):\n",
    "    return torch.from_numpy(x.reshape(shape))\n",
    "\n",
    "\n",
    "def rk45_sampler(model, shape):\n",
    "\n",
    "    rtol = atol = 1e-05\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z0 = torch.randn(shape, device=device)\n",
    "        x = z0.detach().clone()\n",
    "\n",
    "        def ode_func(t, x):\n",
    "            x = from_flattened_numpy(x, shape).to(device).type(torch.float32)\n",
    "            vec_t = torch.ones(shape[0], device=x.device) * t\n",
    "            drift = model(x, vec_t * 999)\n",
    "\n",
    "            return to_flattened_numpy(drift)\n",
    "\n",
    "        solution = integrate.solve_ivp(\n",
    "            ode_func,\n",
    "            (eps, 1),\n",
    "            to_flattened_numpy(x),\n",
    "            rtol=rtol,\n",
    "            atol=atol,\n",
    "            method=\"RK45\",\n",
    "        )\n",
    "        nfe = solution.nfev\n",
    "        x = torch.tensor(solution.y[:, -1]).reshape(shape).type(torch.float32)\n",
    "\n",
    "        return x, nfe\n",
    "\n",
    "\n",
    "def imshow(img, filename):\n",
    "    img = img * 0.3081 + 0.1307\n",
    "    img = np.clip(img, 0, 1)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(npimg[0], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(filename, bbox_inches=\"tight\", pad_inches=0)\n",
    "\n",
    "\n",
    "def save_img_grid(img, filename):\n",
    "    img_grid = torchvision.utils.make_grid(img, nrow=10)\n",
    "    imshow(img_grid, filename)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for batch, _ in dataloader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        z0 = torch.randn_like(batch)\n",
    "        t = torch.rand(batch.shape[0], device=device) * (1 - eps) + eps\n",
    "\n",
    "        t_expand = t.view(-1, 1, 1, 1).repeat(\n",
    "            1, batch.shape[1], batch.shape[2], batch.shape[3]\n",
    "        )\n",
    "        perturbed_data = t_expand * batch + (1 - t_expand) * z0\n",
    "        target = batch - z0\n",
    "\n",
    "        score = model(perturbed_data, t * 999)\n",
    "\n",
    "        losses = torch.square(score - target)\n",
    "        losses = torch.mean(losses.reshape(losses.shape[0], -1), dim=-1)\n",
    "\n",
    "        loss = torch.mean(losses)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "    images, nfe = euler_sampler(model, shape=(100, 1, 28, 28), sample_N=1)\n",
    "    save_img_grid(images, f\"euler_epoch_{epoch + 1}_nfe_{nfe}.png\")\n",
    "\n",
    "    images, nfe = euler_sampler(model, shape=(100, 1, 28, 28), sample_N=2)\n",
    "    save_img_grid(images, f\"euler_epoch_{epoch + 1}_nfe_{nfe}.png\")\n",
    "\n",
    "    images, nfe = euler_sampler(model, shape=(100, 1, 28, 28), sample_N=10)\n",
    "    save_img_grid(images, f\"euler_epoch_{epoch + 1}_nfe_{nfe}.png\")\n",
    "\n",
    "    images, nfe = rk45_sampler(model, shape=(100, 1, 28, 28))\n",
    "    save_img_grid(images, f\"rk45_epoch_{epoch + 1}_nfe_{nfe}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c0f82b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grad312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
