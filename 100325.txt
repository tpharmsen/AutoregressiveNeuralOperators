Possible challenges that come to mind:
- Do we want to embed all the channels (temp, vel, phase, space) into single spatial patches or have each embedding describe a single channel patch?
- periodic boundary conditions dataset needed for valid shifted window self attention at edges of domain
- how to handle different channel inputs? Not all datasets have same channels (think about phase, pressure, temperature?). Masking?
- size symmetry between datasets?
- 2025 Brandstetter unclear middle layer -> classic bottleneck?
- shifting window in swin only valid for single dimension data, becomes increasingly nonvalid for higher dimensions?
- flexible attention?
- norm first like swinv2?
- for window partitioning embedding dimension needs to be exactly patch_size**2, use linears to compress to other embedding sizes? nvm...

Idea:
Combine Unet-Swin model with temporal bundling (BCAT) with strict forward temporal attention

TODO
- Look at difference flex attention BCAT and logit scaling SwinV2
- Dropout
- Validate .transpose(1,2) before projecting
- Positional embedding (learnable/rotary/...)
- Normalisation in Embedding layer